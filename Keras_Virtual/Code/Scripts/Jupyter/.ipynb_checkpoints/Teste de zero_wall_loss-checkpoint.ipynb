{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from auxiliar_functions import TrainingData\n",
    "import re\n",
    "import os\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model, Sequential\n",
    "from keras import backend as K\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial, update_wrapper\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(868,3), activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(20, activation='tanh'))\n",
    "model.add(Dense(3, activation='tanh', name='mag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados para Treinamento\n",
    "ANN_FOLDER = '/home/lucashqr/Documentos/Cursos/Keras Training/'\\\n",
    "             'Virtual/estudos-dissert/Keras_Virtual/Ciclone/ANN_DATA/'\n",
    "\n",
    "DATA = TrainingData(ANN_FOLDER, scaler_dir='../../Models/')\n",
    "\n",
    "\n",
    "# Dados de treinamento\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = DATA.data_gen(test_split=0.25, load_sc=False, save_sc=True)\n",
    "\n",
    "print(X_TRAIN[0, :, :2].reshape(-1, 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xz = X_TRAIN[0, :, :2]\n",
    "print(np.mean(xz, axis=0))\n",
    "#xz = DataFrame(xz)\n",
    "print(xz.shape)\n",
    "wall = []\n",
    "first_line = []\n",
    "A = np.array([np.mean(X_TRAIN[0, :, 0]) - np.max(X_TRAIN[0, :, 1]), 0])\n",
    "for ind,pnt in enumerate(xz):    \n",
    "    B = np.array(pnt) - np.array([np.mean(X_TRAIN[..., 0][0], axis=0), np.mean(X_TRAIN[..., 1])])\n",
    "    B_mag = np.sqrt(np.sum(np.square(B)))\n",
    "    A_mag = np.sqrt(np.sum(np.square(A)))\n",
    "    \n",
    "    if B_mag >= A_mag*0.99:\n",
    "        tmp = [p for p in pnt]\n",
    "        tmp.append(1)\n",
    "        wall.append(np.array(tmp))\n",
    "    else: \n",
    "        wall.append(np.array([0, 0, 0]))\n",
    "    if B_mag >= A_mag*0.92 and B_mag <= A_mag*0.99:\n",
    "        first_line.append([pnt])\n",
    "\n",
    "wall = np.array(wall).reshape(-1, 2) # pontos da parede 'mais afastados do centro'\n",
    "print(wall.shape)\n",
    "first_line = np.array(first_line).reshape(-1, 2)\n",
    "print(first_line.shape)\n",
    "\n",
    "plt.plot(xz[:,0], xz[:,1], 'r*')\n",
    "plt.plot(wall[..., 0], wall[..., 1], 'b*')\n",
    "plt.plot(first_line[..., 0], first_line[..., 1], 'g*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função loss Customizada para magnitude\n",
    "def mag_loss(y_pred, y_true, wall_val):\n",
    "    \"\"\"\n",
    "        File: mag_isolated_prediction.py\n",
    "        Function Name: mag_loss\n",
    "        Summary: Função de custo para rede neural\n",
    "        Description: Loss que adiciona a diferença da magnitude como penalidade\n",
    "    \"\"\"\n",
    "    # Magnitude dos valores reais\n",
    "    M_t = K.sqrt(K.sum(K.square(y_true), axis=-1))\n",
    "    # Magnitude dos valores previstos\n",
    "    M_p = K.sqrt(K.sum(K.square(y_pred), axis=-1))\n",
    "\n",
    "    # Mudar pontos da parede em Booleano, para transformar em binários\n",
    "    # inverter o ponto binários, para que os pontos na parede seja iguais a 0\n",
    "    # e os outros pontos iguais a 1, para multiplicar pelo tensor de vel \n",
    "    wall_val = tf.cast(wall_val, dtype=tf.bool)\n",
    "    wall_val = tf.expand_dims((tf.cast(wall_val, dtype=tf.float32) - 1) * -1, axis=0) # shape (1, 862, 3)\n",
    "    tmp_tens = y_pred * wall_val\n",
    "    # Tecnicamente 'tmp_tens'\n",
    "    print(tmp_tens.get_shape())\n",
    "    Penal = K.sum(K.square(y_pred - tmp_tens), axis=-1) \n",
    "\n",
    "    return K.mean(K.square(y_pred - y_true), axis=-1) + K.abs(M_p - M_t) + Penal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TB = TensorBoard(log_dir='./test_loss/Mag_zero_wall7/')\n",
    "# Interromper Treinamento\n",
    "ES = EarlyStopping(monitor='loss', min_delta=0.000001, patience=175,\n",
    "                   restore_best_weights=True, )\n",
    "\n",
    "# Reduzir taxa de aprendizagem\n",
    "RLRP = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=70, verbose=1,\n",
    "                         min_lr=1E-10)\n",
    "\n",
    "new_mag = update_wrapper(partial(mag_loss, wall_val=wall), mag_loss)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss={'mag':new_mag})\n",
    "\n",
    "print('Iniciando o Treinamento')\n",
    "\n",
    "model.fit(X_TRAIN, Y_TRAIN, epochs=300, batch_size=4, callbacks=[ES, RLRP, TB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados para comparação com caso original\n",
    "BASE_DIR ='./test_loss/Mag_zero_wall7/'\n",
    "          \n",
    "print(f\"Gerando dados de previsão em {BASE_DIR}\")\n",
    "scaler_dict = DATA.return_scaler(load_sc=True)\n",
    "VEL_ARR = np.array([[10.0]*868]).reshape(-1, 1)\n",
    "VEL_ARR = scaler_dict['U_in'].transform(VEL_ARR).reshape(1, -1, 1)\n",
    "\n",
    "# Valores previstos para Ux, Uy e Uz\n",
    "PREDICs = model.predict(X_TRAIN[0, :].reshape(1, -1, 3))\n",
    "print([p.shape for p in PREDICs])\n",
    "\n",
    "\n",
    "# Retornando os dados para a escala anterior\n",
    "Ux = DataFrame(scaler_dict['Ux_scaler'].inverse_transform(PREDICs[..., 0]).reshape(-1), columns=['U:0'])\n",
    "Uy = DataFrame(scaler_dict['Uy_scaler'].inverse_transform(PREDICs[..., 1]).reshape(-1), columns=['U:1'])\n",
    "Uz = DataFrame(scaler_dict['Uz_scaler'].inverse_transform(PREDICs[..., 2]).reshape(-1), columns=['U:2'])\n",
    "\n",
    "# Inserindo valor dos pontos de Y\n",
    "XYZ = read_csv(os.scandir(ANN_FOLDER).__next__().path)[['Points:0', 'Points:1', 'Points:2']]\n",
    "\n",
    "# Geração de arquivo .CSV para leitura\n",
    "FILENAME = f'NEW_SLICE_10_Isolated.csv'\n",
    "\n",
    "SLICE_DATA = concat([Ux, Uy, Uz, XYZ], sort=True, axis=1)\n",
    "\n",
    "# Escrevendo o header no formato do paraview\n",
    "with open(BASE_DIR+FILENAME, 'w') as filename:\n",
    "    HEADER = ''\n",
    "    for col in list(SLICE_DATA.columns):\n",
    "        HEADER += '\\\"' + col + '\\\",'\n",
    "    filename.write(HEADER[:-1])\n",
    "    filename.write('\\n')\n",
    "\n",
    "SLICE_DATA.to_csv(BASE_DIR + FILENAME, index=False, header=False, mode='a')\n",
    "print(\"Dados de previsão copiados!\")\n",
    "\n",
    "\n",
    "# Diferença do valor previsto e o caso original\n",
    "print(\"Calculando diferença...\")\n",
    "ORIGIN_DATA = read_csv(ANN_FOLDER+'SLICE_DATA_U_10_0.csv')\n",
    "\n",
    "DIFF = SLICE_DATA[['U:0', 'U:1', 'U:2']] - ORIGIN_DATA[['U:0', 'U:1', 'U:2']]\n",
    "\n",
    "RESULT_DATA = concat([DIFF, XYZ], axis=1)\n",
    "\n",
    "print('Escrevendo dados DIFERENÇA')\n",
    "RESULT_DATA.to_csv(BASE_DIR + 'DIFF_SLICE_U_10.csv', index=False)\n",
    "print('Dados de diferença copiados!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(BASE_DIR+'zero_wall_loss', overwrite=True, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
